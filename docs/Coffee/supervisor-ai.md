---
description: AGI and the path to the Singularity
draft: true
---

# The Supervisor AI, AGI, and the path to the Singularity

Artificial general intelligence (AGI) is the (hypothetical) ability of a machine to understand or learn any intellectual task that a human being can. 

Many people think that machines will never be as smart as humans. Instead of beating that dead-horse, let's assume it's going to happen so that we can explore another interesting concept - the singularity.

## The Singularity

The singularity is point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization. 

Imagine that you made a machine with just one task: make itself better. At the start it might just be a piece of software, and you - being a smart programmer - create this program so that it can re-write it's own code. 

It will be a bit dumb at first, and you - being a smart programmer - realise this. You devise a simple system that allows dumb things to get smarter: evolution. You program your software to "reproduce", adding just minor changes each time th producing "Generation 1" of


The changes need to be random though - so where are we going to get a bunch of random code? Simple - an AI that is trained on billions of lines of 

- Uses GPT 3 prompt to create a programming challenge
- Uses Copilot to code up a program
- Asseses whether the program solves the problem
- Deletes the program which fail. Duplicates the gen 1, but also creates merges of the winning solutions.

## The path to the Singularity

## Supervisor AI

In the future there will be an AI which is responsible for:
1. coming up with goals
2. employing specialised AI algorithms to solve those goals
3. measuring the changes
4. improving the AI algorithms

Many people today are focused on the creation of specialised algorithms. Very few are working on how AI will formulate its goals.

There is a lot of apprehension about the future of AI with respect to humanity's survival. The speculation is that AI will soon be more intelligent than humans it may decide that we are no longer required for its survival and, in fact, the world may be better off with a reduction in our population. 

Of course AI is already more intelligent or advanced than humans in a lot of domains - playing chess and Go, making calculations - but this isn't the AI that worries people. The AI that people worry about is called Advanced General Intelligence (or AGI). This is the type of intelligence that can make changes to it's own codebase and apply its knowlege to a plethora of situations rather than one specific domain. 

I still find this classification too broad. Many of the current AI (kind of) already make improvements to themselves. And some algorithms are already used in multiple domains.


## The actual scary part of AGI 

The real problem that we should be worried about is

> _AI that comes up with it's own goals_

This is an unbelivably trivial thing for a human to do. Give a 3-year-old a box of toys and watch as they spend the next 2 hours coming up with silly games with random rules. These seem like pretty pointless and benign rules, but the fact that they can do it is far beyond where AI is. For now.

Try giving a computer to any current AI algorithm and they will do the only thing they have been trained to do.

__At the moment AI is good at solving specific problems. It is not good at coming up with its own goals.__

Each AI algorithm is like an actor in play, blindly reciting their script.


## The Actor Model

The actor analogy is actually very apt. In computer science, "The Actor Model" is a method of creating very discrete programs can operate in a much larger web of similar or different actors. To quote wikipedia:

> In response to a message that it receives, an actor can: make local decisions, create more actors, send more messages, and determine how to respond to the next message received. Actors may modify their own private state, but can only affect each other through messages.

As an example,

This model is used extensively in distributed systems because it is extremely scalable and fault-tolerant. 


## Resources

- [OmniNet:- A unified architecture for multi-modal multi-task learning](https://news.ycombinator.com/item?id=20479366)